{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Text from URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREPARATION \n",
    "CSV file in the current working directory as input. File contains multiple rows of data with columns of ContactID, OrganizationName and Website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**ACTIVTY 1\n",
    "Requesting data from the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, the requests.get() method will request the page from website using https protocol and load the page into the object “page”. The next line of code will move the HTML code to String html_code. This function will extract the data from a website but it is still in HTML format which is far different than the actual text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ACTIVITY 2 \n",
    "Extracting text from HTML page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in CSV file with a URL for each organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\CMH\\Initiatives\\MakingConnections\\JupyterNotebooks\\ExtractHTML_Text\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://epiloglaser.com\n",
      "  ContactID                   OrganizationName  \\\n",
      "0         5  University of Colorado at Boulder   \n",
      "1         9                         AudioPixel   \n",
      "2        23                               Ball   \n",
      "3        43                       Epilog Laser   \n",
      "4        51                     Barnes & Noble   \n",
      "\n",
      "                                        Website  \n",
      "0                           http://colorado.edu  \n",
      "1                         http://audiopixel.com  \n",
      "2                               http://ball.com  \n",
      "3                        http://epiloglaser.com  \n",
      "4  https://stores.barnesandnoble.com/store/2718  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('DATASET_CORE_CMHDirectory_SubsetOf2019_0118.csv', dtype=object)\n",
    "print(data.loc[3, 'Website'])\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'charmap' codec can't encode character '\\u0103' in position 44: character maps to <undefined>\n",
      "'charmap' codec can't encode characters in position 39-40: character maps to <undefined>\n",
      "'charmap' codec can't encode characters in position 39-41: character maps to <undefined>\n",
      "'charmap' codec can't encode character '\\u0103' in position 44: character maps to <undefined>\n",
      "'charmap' codec can't encode characters in position 39-40: character maps to <undefined>\n",
      "'charmap' codec can't encode characters in position 39-41: character maps to <undefined>\n",
      "'charmap' codec can't encode character '\\u2011' in position 58: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('OUTPUT_AdditionalURLs.csv', mode='w') as file:\n",
    "    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    writer.writerow(['ContactID', 'OrganizationName', 'URLUsed', 'NameToFoundURL', 'FoundURL'])\n",
    "\n",
    "    anchortags= []\n",
    "    for index,row in data.iterrows():\n",
    "        orgID = data.loc[index, 'ContactID']\n",
    "        orgName = data.loc[index, 'OrganizationName']\n",
    "        orgURL = data.loc[index, 'Website']\n",
    "        try:\n",
    "            page = requests.get(orgURL)     #to extract page from website\n",
    "            html_code = page.content        #to extract html code from page\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_code, 'html.parser')  #Parse html code\n",
    "            anchortags = soup.find_all([\"a\"])               #find all anchor tags\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    " \n",
    "        for link in soup.find_all('a'):\n",
    "            foundURL = link.get('href')\n",
    "            nameToFoundURL = link.text.strip()           \n",
    "            keep = True\n",
    "\n",
    "            if foundURL:\n",
    "                foundURL = bytes(foundURL, 'utf-8').decode('utf-8', 'ignore')\n",
    "            \n",
    "            if not foundURL:\n",
    "                keep = False\n",
    "            elif foundURL[0] == '#':\n",
    "                keep = False\n",
    "            elif \"\\\\\" in foundURL:\n",
    "                keep = False\n",
    "            elif foundURL[0] == '/':\n",
    "                foundURL = orgURL + foundURL\n",
    "                           \n",
    "            if keep:    \n",
    "                try:\n",
    "                    #Writing what was found to the our CSV\n",
    "                    writer.writerow([orgID, orgName, orgURL, nameToFoundURL,foundURL])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
